"""
AI Life OS å¼‚å¸¸å®šä¹‰æ¨¡å—ã€‚

å®šä¹‰ç³»ç»Ÿä¸­æ‰€æœ‰è‡ªå®šä¹‰å¼‚å¸¸çš„å±‚æ¬¡ç»“æ„ï¼š
- AILifeError: åŸºç±»ï¼Œæ‰€æœ‰å·²çŸ¥é”™è¯¯
- ConfigError: é…ç½®æ–‡ä»¶é”™è¯¯
- StateError: çŠ¶æ€ç›¸å…³é”™è¯¯
- InterruptError: ç”¨æˆ·ä¸»åŠ¨ä¸­æ–­
- LLMError: æ¨¡å‹è°ƒç”¨ç›¸å…³é”™è¯¯
"""
from typing import Optional


class AILifeError(Exception):
    """AI Life OS åŸºç¡€å¼‚å¸¸ç±»ã€‚

    æ‰€æœ‰ç³»ç»Ÿå†…å·²çŸ¥é”™è¯¯éƒ½ç»§æ‰¿è‡ªæ­¤ç±»ã€‚
    æ•è·æ­¤ç±»å¯ä»¥å¤„ç†æ‰€æœ‰é¢„æœŸçš„é”™è¯¯æƒ…å†µã€‚
    """

    def __init__(self, message: str, hint: Optional[str] = None):
        """
        Args:
            message: é”™è¯¯æè¿°
            hint: å¯¹ç”¨æˆ·çš„æ“ä½œå»ºè®®
        """
        super().__init__(message)
        self.message = message
        self.hint = hint

    def get_user_message(self) -> str:
        """è¿”å›ç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯ã€‚"""
        if self.hint:
            return f"{self.message}\nğŸ’¡ å»ºè®®: {self.hint}"
        return self.message


class ConfigError(AILifeError):
    """é…ç½®æ–‡ä»¶é”™è¯¯ã€‚

    å½“é…ç½®æ–‡ä»¶ç¼ºå¤±ã€æ ¼å¼é”™è¯¯æˆ–å†…å®¹éæ³•æ—¶æŠ›å‡ºã€‚
    """

    def __init__(self, message: str, config_path: Optional[str] = None):
        hint = f"è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶: {config_path}" if config_path else "è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶æ ¼å¼"
        super().__init__(message, hint)
        self.config_path = config_path


class StateError(AILifeError):
    """çŠ¶æ€ç›¸å…³é”™è¯¯ã€‚

    å½“çŠ¶æ€é‡å»ºå¤±è´¥æˆ–äº‹ä»¶æ•°æ®æ ¼å¼é”™è¯¯æ—¶æŠ›å‡ºã€‚
    """

    def __init__(self, message: str, corrupted_data: Optional[str] = None):
        hint = "çŠ¶æ€å¯èƒ½å·²æŸåï¼Œå»ºè®®æ£€æŸ¥ event_log.jsonl"
        super().__init__(message, hint)
        self.corrupted_data = corrupted_data


class InterruptError(AILifeError):
    """ç”¨æˆ·ä¸»åŠ¨ä¸­æ–­ã€‚

    å½“ç”¨æˆ·ä¸»åŠ¨ç»ˆæ­¢æ“ä½œï¼ˆé Crashï¼‰æ—¶æŠ›å‡ºã€‚
    è¿™æ˜¯é¢„æœŸè¡Œä¸ºï¼Œä¸åº”è§†ä¸ºé”™è¯¯ã€‚
    """

    def __init__(self, message: str = "ç”¨æˆ·ä¸»åŠ¨ä¸­æ–­æ“ä½œ"):
        super().__init__(message, hint=None)


class LLMError(AILifeError):
    """LLM è°ƒç”¨ç›¸å…³é”™è¯¯çš„åŸºç±»ã€‚

    å½“æ¨¡å‹è°ƒç”¨å¤±è´¥æ—¶æŠ›å‡ºï¼ŒåŒ…å«è°ƒç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
    """

    def __init__(
        self,
        message: str,
        provider: Optional[str] = None,
        model_name: Optional[str] = None,
        endpoint: Optional[str] = None
    ):
        self.provider = provider or "unknown"
        self.model_name = model_name or "unknown"
        self.endpoint = endpoint

        context = f"[{self.provider}/{self.model_name}]"
        full_message = f"{context} {message}"

        super().__init__(full_message)

    def get_user_message(self) -> str:
        """è¿”å›åŒ…å«æ¨¡å‹ä¿¡æ¯çš„ç”¨æˆ·å‹å¥½æ¶ˆæ¯ã€‚"""
        base = f"æ¨¡å‹è°ƒç”¨å¤±è´¥ ({self.provider}/{self.model_name}): {self.message}"
        if self.hint:
            return f"{base}\nğŸ’¡ å»ºè®®: {self.hint}"
        return base


class LLMConnectionError(LLMError):
    """æ— æ³•è¿æ¥åˆ° LLM æœåŠ¡ã€‚"""

    def __init__(
        self,
        provider: Optional[str] = None,
        model_name: Optional[str] = None,
        endpoint: Optional[str] = None
    ):
        message = "æ— æ³•è¿æ¥åˆ°æ¨¡å‹æœåŠ¡"
        super().__init__(message, provider, model_name, endpoint)

        if provider == "ollama":
            self.hint = "è¯·ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ (ollama serve)"
        elif provider == "openai":
            self.hint = "è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ– API ç«¯ç‚¹é…ç½®"
        else:
            self.hint = "è¯·æ£€æŸ¥æ¨¡å‹æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ"


class LLMAuthError(LLMError):
    """LLM é‰´æƒå¤±è´¥ã€‚"""

    def __init__(
        self,
        provider: Optional[str] = None,
        model_name: Optional[str] = None,
        endpoint: Optional[str] = None
    ):
        message = "æ¨¡å‹é‰´æƒå¤±è´¥"
        super().__init__(message, provider, model_name, endpoint)
        self.hint = "è¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®é…ç½®"


class LLMTimeoutError(LLMError):
    """LLM è°ƒç”¨è¶…æ—¶ã€‚"""

    def __init__(
        self,
        provider: Optional[str] = None,
        model_name: Optional[str] = None,
        endpoint: Optional[str] = None,
        timeout_seconds: Optional[float] = None
    ):
        message = "æ¨¡å‹è°ƒç”¨è¶…æ—¶"
        if timeout_seconds:
            message = f"æ¨¡å‹è°ƒç”¨è¶…æ—¶ ({timeout_seconds}ç§’)"
        super().__init__(message, provider, model_name, endpoint)
        self.timeout_seconds = timeout_seconds
        self.hint = "å¯èƒ½æ˜¯ç½‘ç»œæ…¢æˆ–æ¨¡å‹å“åº”æ—¶é—´é•¿ï¼Œè¯·ç¨åé‡è¯•"


class LLMRateLimitError(LLMError):
    """LLM è¯·æ±‚é¢‘ç‡é™åˆ¶ã€‚"""

    def __init__(
        self,
        provider: Optional[str] = None,
        model_name: Optional[str] = None,
        endpoint: Optional[str] = None,
        retry_after: Optional[int] = None
    ):
        message = "è¯·æ±‚é¢‘ç‡è¶…é™"
        super().__init__(message, provider, model_name, endpoint)
        self.retry_after = retry_after
        if retry_after:
            self.hint = f"è¯·åœ¨ {retry_after} ç§’åé‡è¯•"
        else:
            self.hint = "è¯·ç¨åé‡è¯•"
